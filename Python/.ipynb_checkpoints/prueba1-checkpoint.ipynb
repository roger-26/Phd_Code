{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) SenseTime. All Rights Reserved.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from pytracking.refine_modules.refine_module import RefineModule\n",
    "from pytracking.RF_utils import bbox_clip\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "\n",
    "class DBLoader(object):\n",
    "    \"\"\" Debug Data Loader \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.gt_file = os.path.join(self.data_dir, 'groundtruth.txt')\n",
    "        self.curr_idx = 0\n",
    "        self.im_paths = glob.glob(os.path.join(self.data_dir, 'img/*.jpg'))\n",
    "        self.im_paths.sort()\n",
    "        self.init_box = self.get_init_box()\n",
    "\n",
    "    def get_init_box(self):\n",
    "        gt = np.genfromtxt(self.gt_file, delimiter=',')\n",
    "        gt = list(map(int, gt[0].tolist()))\n",
    "        return np.asarray(gt)\n",
    "\n",
    "    def region(self):\n",
    "        return self.init_box\n",
    "\n",
    "    def frame(self):\n",
    "        im_path = self.im_paths[self.curr_idx] if self.curr_idx < len(self.im_paths) else None\n",
    "        # print('pumping {}'.format(im_path))\n",
    "        self.curr_idx += 1\n",
    "        return im_path, None\n",
    "\n",
    "\n",
    "def get_axis_aligned_bbox(region):\n",
    "    \"\"\" convert region to (cx, cy, w, h) that represent by axis aligned box\n",
    "    \"\"\"\n",
    "    nv = region.size\n",
    "    if nv == 8:\n",
    "        cx = np.mean(region[0::2])\n",
    "        cy = np.mean(region[1::2])\n",
    "        x1 = min(region[0::2])\n",
    "        x2 = max(region[0::2])\n",
    "        y1 = min(region[1::2])\n",
    "        y2 = max(region[1::2])\n",
    "        A1 = np.linalg.norm(region[0:2] - region[2:4]) * \\\n",
    "             np.linalg.norm(region[2:4] - region[4:6])\n",
    "        A2 = (x2 - x1) * (y2 - y1)\n",
    "        s = np.sqrt(A1 / A2)\n",
    "        w = s * (x2 - x1) + 1\n",
    "        h = s * (y2 - y1) + 1\n",
    "    else:\n",
    "        x = region[0]\n",
    "        y = region[1]\n",
    "        w = region[2]\n",
    "        h = region[3]\n",
    "        cx = x + w / 2\n",
    "        cy = y + h / 2\n",
    "    return cx, cy, w, h\n",
    "\n",
    "\n",
    "def get_dimp(img, init_box, model_path):\n",
    "    \"\"\" set up DiMPsuper as the base tracker \"\"\"\n",
    "    from pytracking.parameter.dimp.super_dimp_demo import parameters\n",
    "    from pytracking.tracker.dimp.dimp import DiMP\n",
    "\n",
    "    params = parameters(model_path)\n",
    "    params.visualization = True\n",
    "    params.debug = False\n",
    "    params.visdom_info = {'use_visdom': False, 'server': '127.0.0.1', 'port': 8097}\n",
    "    tracker = DiMP(params)\n",
    "\n",
    "    H, W, _ = img.shape\n",
    "    cx, cy, w, h = get_axis_aligned_bbox(np.array(init_box))\n",
    "    gt_bbox_ = [cx - (w - 1) / 2, cy - (h - 1) / 2, w, h]\n",
    "    '''Initialize'''\n",
    "    gt_bbox_np = np.array(gt_bbox_)\n",
    "    gt_bbox_torch = torch.from_numpy(gt_bbox_np.astype(np.float32))\n",
    "    init_info = {}\n",
    "    init_info['init_bbox'] = gt_bbox_torch\n",
    "    tracker.initialize(img, init_info)\n",
    "\n",
    "    return tracker\n",
    "\n",
    "\n",
    "def get_ar(img, init_box, ar_path):\n",
    "    \"\"\" set up Alpha-Refine \"\"\"\n",
    "    selector_path = 0\n",
    "    sr = 2.0;\n",
    "    input_sz = int(128 * sr)  # 2.0 by default\n",
    "    RF_module = RefineModule(ar_path, selector_path, search_factor=sr, input_sz=input_sz)\n",
    "    RF_module.initialize(img, np.array(init_box))\n",
    "    return RF_module\n",
    "\n",
    "\n",
    "def demo(base_path, ar_path, data_dir, res_folder):\n",
    "    debug_loader = DBLoader(data_dir=data_dir)\n",
    "\n",
    "    handle = debug_loader\n",
    "    init_box = handle.region()\n",
    "    imagefile, _ = handle.frame()\n",
    "    img = cv2.cvtColor(cv2.imread(imagefile), cv2.COLOR_BGR2RGB)  # Right\n",
    "    H, W, _ = img.shape\n",
    "\n",
    "    \"\"\" Step 1: set up base tracker and Alpha-Refine \"\"\"\n",
    "    tracker = get_dimp(img, init_box, base_path)\n",
    "    RF_module = get_ar(img, init_box, ar_path)\n",
    "\n",
    "    # OPE tracking\n",
    "    prediction = []\n",
    "    while True:\n",
    "        imagefile, _ = handle.frame()\n",
    "        if not imagefile:\n",
    "            break\n",
    "        img = cv2.cvtColor(cv2.imread(imagefile), cv2.COLOR_BGR2RGB)  # Right\n",
    "\n",
    "        \"\"\" Step 2: base tracker prediction \"\"\"\n",
    "        # track with base tracker\n",
    "        outputs = tracker.track(img)\n",
    "        pred_bbox = outputs['target_bbox']\n",
    "\n",
    "        \"\"\" Step 3: refine tracking results with Alpha-Refine \"\"\"\n",
    "        pred_bbox = RF_module.refine(img, np.array(pred_bbox))\n",
    "\n",
    "        \"\"\" Step 4: update base tracker's state with refined result \"\"\"\n",
    "        x1, y1, w, h = pred_bbox.tolist()\n",
    "        x1, y1, x2, y2 = bbox_clip(x1, y1, x1 + w, y1 + h, (H, W))\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        new_pos = torch.from_numpy(np.array([y1 + h / 2, x1 + w / 2]).astype(np.float32))\n",
    "        new_target_sz = torch.from_numpy(np.array([h, w]).astype(np.float32))\n",
    "        new_scale = torch.sqrt(new_target_sz.prod() / tracker.base_target_sz.prod())\n",
    "\n",
    "        tracker.pos = new_pos.clone()\n",
    "        tracker.target_sz = new_target_sz\n",
    "        tracker.target_scale = new_scale\n",
    "\n",
    "        # visualization\n",
    "        pred_bbox = list(map(int, pred_bbox))\n",
    "        prediction.append(pred_bbox)\n",
    "        # _img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # cv2.rectangle(_img, (pred_bbox[0], pred_bbox[1]),\n",
    "        #              (pred_bbox[0] + pred_bbox[2], pred_bbox[1] + pred_bbox[3]), (0, 255, 255), 3)\n",
    "        # cv2.imshow('', _img)\n",
    "        # key = cv2.waitKey(1)\n",
    "        # if key == ord('q'):\n",
    "        #    exit(0)\n",
    "\n",
    "    res_name = data_dir.split('/')[-1]\n",
    "    print(os.path.join(res_folder, res_name + '.txt'))\n",
    "    np.savetxt(os.path.join(res_folder, res_name + '.txt'), np.asarray(prediction).astype(int), fmt='%i', delimiter=\",\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # path to model_file of base tracker - model can be download from:\n",
    "    # https://drive.google.com/open?id=1qDptswis2FxihLRYLVRGDvx6aUoAVVLv\n",
    "    base_path = '/home/r/Downloads/AlphaRefine-master/super_dimp.pth.tar'\n",
    "\n",
    "    # path to model_file of Alpha-Refine - the model can be download from\n",
    "    # https://drive.google.com/file/d/1drLqNq4r9g4ZqGtOGuuLCmHJDh20Fu1m/view\n",
    "    ar_path = '/home/r/Downloads/AlphaRefine-master/SEcmnet_ep0040-c.pth.tar'\n",
    "\n",
    "    # data_folder = '/home/r/Current_Work_Phd/set1K_deblur'\n",
    "    # data_folder = '/home/r/Current_Work_Phd/set1K_images'\n",
    "    data_folder = '/home/r/Current_Work_Phd/set_1385_VariacionResolucion/Videos_1_5_resolution'\n",
    "\n",
    "    res_folder = '/home/r/Current_Work_Phd/set_1385_VariacionResolucion/results/1_5_Alpharefine'\n",
    "    # res_folder = 'C:\\\\Users\\\\juanp\\\\Documents\\\\RogerHernan\\\\trackers\\\\new_trackers\\\\AlphaRefine\\\\results'\n",
    "\n",
    "    folders = glob.glob(os.path.join(data_folder, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r/.local/lib/python3.8/site-packages/torch/nn/functional.py:2503: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /tmp/torch_extensions as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /tmp/torch_extensions/_prroi_pooling/build.ninja...\n",
      "Building extension module _prroi_pooling...\n",
      "Loading extension module _prroi_pooling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r/.local/lib/python3.8/site-packages/torch/nn/functional.py:2503: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/r/Current_Work_Phd/set_1385_VariacionResolucion/results/1_5_Alpharefine/4097ExFo_IndPPP_LQ_C1.txt\n",
      "/home/r/Current_Work_Phd/set_1385_VariacionResolucion/results/1_5_Alpharefine/0171Exp_IndLPP_MQ_C2.txt\n"
     ]
    }
   ],
   "source": [
    "    for data_dir in folders:\n",
    "        demo(base_path, ar_path, data_dir, res_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
